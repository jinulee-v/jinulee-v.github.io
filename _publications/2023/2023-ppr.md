---
title:          "Learning to Rank Generation with Pairwise Partial Rewards"
date:           2023-12-01 00:00:00 -1200
selected:       true
pub:            "EMNLP"
pub_date:       "2023"
pub_last:       "Main"
# abstract: >-
#   This paper studies the use of reinforcement learning for conditional text generation, which overcomes the limitation of the prevalent supervised maximum likelihood estimation approach. However, it still suffers from challenges including the large action space and the delayed reward, as the reward can be computed only after an entire sequence is generated. To address these challenges, we propose a method that provides partial rewards for intermediate actions taken on partial sequences. This enables the model to promptly prioritize actions that lead to the generation of more desirable sequences. Our methodâ€™s key contribution lies in its focus on distinguishing relatively more desirable actions rather than striving to precisely estimate pointwise values for arbitrary partial sequences. Instead, our model learns to discern the relative desirability between pairs of actions, or rank actions in a pairwise manner, only when necessary and feasible. This is materialized in an efficient way by leveraging the prefix tree constructed from the sampled sequences. Experimental results on paraphrase generation and constrained machine translation tasks showcase the effectiveness of our method.
cover:          /assets/images/covers/2023-ppr.png
authors:
- Youngwon Lee*
- Jinu Lee*
- Seung-won Hwang
links:
  Paper: https://aclanthology.org/2023.emnlp-main.371/
---